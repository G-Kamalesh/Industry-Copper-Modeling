# Industry-Copper-Modeling
Creating Regression and Classification Model for Predicting Selling Price and Status

Domain: Manufacturing

Skills needed: Python scripting, Data Preprocessing, EDA, Streamlit, Model building & evaluation

# Introduction
The Industrial Copper Modeling project focuses on predicting the selling price and status (won or lost) in the industrial copper market using machine learning regression and classification algorithms. By exploring the dataset, performing data cleaning and preprocessing, and applying various machine learning techniques, we aim to develop models that can accurately predict the selling price and status in the copper market.

# Requirements
To run this project, the following libraries are needed:
* NumPy: A library for numerical computations in Python.
* Pandas: A library for data manipulation and analysis.
* Scikit-learn: A machine learning library that provides various regression and classification algorithms.
* Matplotlib: A plotting library for creating visualizations.
* Seaborn: A data visualization library built on top of Matplotlib.
* Streamlit: A Python framework for data scientists and AI/ML engineers to deliver interactive data apps. 

Make sure these libraries are installed in your Python environment before running the project.

# 1. Data Preprocessing
* Gain a deep understanding of dataset variables and types.
* Handle missing data with appropriate strategies.
* Prepare categorical features through encoding and data type conversion.
* Address skewness and ensure data balance.
* Identify and manage outliers.
* Resolve date discrepancies for data integrity.

# 2. Exploratory Data Analysis (EDA) and Feature Engineering
* Visualize and correct skewness.
* Identify and rectify outliers.
* Feature improvement and creation for more effective modeling.

# 3. Classification
* Success and Failure Classification: Focusing on 'Won' and 'Lost' status.
* Algorithm Assessment: Evaluating algorithms for classification.
* Algorithm Selection: Choosing the Random Forest Classifier.
* Hyperparameter Tuning: Fine-tuning with RandomizedSearchCV and cross-validation.
* Model Accuracy and Metrics: Assessing performance and metrics.
* Model Persistence: Saving the model for future use.

# 4.Regression
* Algorithm Assessment: Identifying algorithms for regression.
* Algorithm Selection: Opting for the Random Forest Regressor.
* Hyperparameter Tuning: Fine-tuning with RandomizedSearchCV and cross-validation.
* Model Accuracy and Metrics: Evaluating regression model performance.
* Model Persistence: Saving the regression model for future applications.

# 5. Model Evaluation Result
* Classification: Achieved 95.41% accuracy with Random Forest Classifier.
* Regression: Achieved 93.8% accuracy with Random Forest Regressor.

# 6. Streamlit web app
* A interactive GUI is created to get input from user and feed it to model and displays the result.
* We can even host this data app in cloud platform too.

# Contact
Linkedin:www.linkedin.com/in/g-kamaleashwar-28a2802ba
